---
youku_id: XMTYyMTY1MjMwOA
youtube_id: JCBe_yjDmY8
bilibili_id: 16008385
description: 这一次我们会说道 CNN 代码中怎么定义 Convolutional 的层 和怎样进行 pooling.
chapter: 5
title: CNN 卷积神经网络 2
author: 年拾柒
date: 2016-11-3
post-headings:
  - 定义卷积层的 weight bias
  - 定义 pooling
---


学习资料:
  * [相关代码](https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT/tf18_CNN2){:target="_blank"}
  * 为 TF 2017 打造的[新版可视化教学代码](https://github.com/MorvanZhou/Tensorflow-Tutorial){:target="_blank"}
  * 机器学习-简介系列 [什么是 CNN]({% link _tutorials/machine-learning/ML-intro/2-2-CNN.md %})
  
这一次我们会说道 CNN 代码中怎么定义 Convolutional 的层和怎样进行 pooling.

基于上一次卷积神经网络的介绍，我们在代码中实现一个基于MNIST数据集的例子 

{% include assign-heading.html %}


首先我们导入 

```python
import tensorflow as tf
```

采用的数据集依然是`tensorflow`里面的`mnist`数据集

我们需要先导入它

```python
python from tensorflow.examples.tutorials.mnist import input_data
```

本次课程代码用到的数据集就是来自于它 

```python
mnist=input_data.read_data_sets('MNIST_data',one_hot=true)
```
接着呢，我们定义`Weight`变量，输入`shape`，返回变量的参数。其中我们使用`tf.truncted_normal`产生随机变量来进行初始化:

```python
def weight_variable(shape): 
	inital=tf.truncted_normal(shape,stddev=0.1)
	return tf.Variable(initial)
```

同样的定义`biase`变量，输入`shape` ,返回变量的一些参数。其中我们使用`tf.constant`常量函数来进行初始化:

```python
def bias_variable(shape): 
	initial=tf.constant(0.1,shape=shape) 
	return tf.Variable(initial)
```

定义卷积，`tf.nn.conv2d`函数是`tensoflow`里面的二维的卷积函数，`x`是图片的所有参数，`W`是此卷积层的权重，然后定义步长`strides=[1,1,1,1]`值，`strides[0]`和`strides[3]`的两个1是默认值，中间两个1代表padding时在x方向运动一步，y方向运动一步，padding采用的方式是`SAME`。 

```python
def conv2d(x,W):
	return tf.nn.conv2d(x,W,strides=[1,1,1,1]，padding='SAME') 
```

{% include google-in-article-ads.html %}

{% include assign-heading.html %}


接着定义池化`pooling`，为了得到更多的图片信息，padding时我们选的是一次一步，也就是`strides[1]=strides[2]=1`，这样得到的图片尺寸没有变化，而我们希望压缩一下图片也就是参数能少一些从而减小系统的复杂度，因此我们采用`pooling`来稀疏化参数，也就是卷积神经网络中所谓的下采样层。`pooling `有两种，一种是最大值池化，一种是平均值池化，本例采用的是最大值池化`tf.max_pool()`。池化的核函数大小为2x2，因此`ksize=[1,2,2,1]`，步长为2，因此`strides=[1,2,2,1]`:

```python
def max_poo_2x2(x): 
	return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1])
```


好啦，如果你对本节课内容已经了解，下一次课我们将构建卷积神经网络的架构~

